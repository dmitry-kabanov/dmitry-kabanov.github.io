<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>tensorflow on Website of Dmitry Kabanov</title>
    <link>https://dmitrykabanov.com/tags/tensorflow/</link>
    <description>Recent content in tensorflow on Website of Dmitry Kabanov</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jul 2020 12:19:00 +0200</lastBuildDate>
    
	<atom:link href="https://dmitrykabanov.com/tags/tensorflow/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Saving state for tf.function-decorated functions</title>
      <link>https://dmitrykabanov.com/blog/2020/03-saving-state-tf-function/</link>
      <pubDate>Fri, 31 Jul 2020 12:19:00 +0200</pubDate>
      
      <guid>https://dmitrykabanov.com/blog/2020/03-saving-state-tf-function/</guid>
      <description>When you decorate a function with `tf.function` decorator, sometimes you need to keep state between invocations of this function.
The problem here is that the changes to the state will not be visible in the decorated function if the state is saved in the Python variables.
To illustrate the problem, Tensorflow 2.2 is used:
import tensorflow as tf print(tf.__version__) 2.2.0 To see the problem, let&amp;rsquo;s consider the following code. Let&amp;rsquo;s assume that we need to scale a given Tensor `x` and we do it using `tf.</description>
    </item>
    
    <item>
      <title>Using `tf.function` for performance in Tensorflow 2</title>
      <link>https://dmitrykabanov.com/blog/2020/02-tf-function-performance/</link>
      <pubDate>Tue, 28 Jul 2020 13:54:00 +0200</pubDate>
      
      <guid>https://dmitrykabanov.com/blog/2020/02-tf-function-performance/</guid>
      <description>Tensorflow 2 uses so called Eager mode by default. In this mode, it is easy to define tensors interactively, for example, in ipython and see their values. However, in Eager mode the execution is slow, which becomes noticable during model training.
Tensorflow 2 offers another mode of execution called Graph mode. In this mode, first the computational graph is created and then used to compute loss function and its gradient. This mode is more performance efficient.</description>
    </item>
    
  </channel>
</rss>